# OpenAI API Configuration (Required for LLM integration)
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_MODEL=gpt-3.5-turbo
OPENAI_MAX_TOKENS=2000
OPENAI_TEMPERATURE=0.7

# Academic API Keys (Optional - for higher rate limits and better access)
SEMANTIC_SCHOLAR_API_KEY=your-semantic-scholar-api-key-here
PUBMED_API_KEY=your-pubmed-api-key-here
CROSSREF_API_KEY=your-crossref-api-key-here
OPENALEX_API_KEY=your-openalex-api-key-here

# Server Configuration
HOST=0.0.0.0
PORT=8000
DEBUG=True
LOG_LEVEL=INFO

# Database Configuration (if using database features)
DATABASE_URL=sqlite:///./research_papers.db

# CORS Configuration
CORS_ORIGINS=http://localhost:3000,http://localhost:5173,https://your-frontend-domain.vercel.app

# Rate Limiting
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=3600

# Cache Configuration
REDIS_URL=redis://localhost:6379/0
CACHE_TTL=3600

# Monitoring & Analytics
SENTRY_DSN=your-sentry-dsn-here
ENABLE_METRICS=true

# Paper Generation Settings
DEFAULT_MAX_PAPERS=50
DEFAULT_CITATION_STYLE=apa
DEFAULT_PAPER_LENGTH=medium